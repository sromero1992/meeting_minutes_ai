{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:/Users/ssromerogon/Document\n",
      "[nltk_data]     s/vscode_working_dir/meeting_minutes_processing/...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:/Users/ssromerogon/Docu\n",
      "[nltk_data]     ments/vscode_working_dir/meeting_minutes_processing/..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:/Users/ssromerogon/Docu\n",
      "[nltk_data]     ments/vscode_working_dir/meeting_minutes_processing/..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "100%|█████████████████████████████████████| 2.88G/2.88G [03:31<00:00, 14.6MiB/s]\n",
      "c:\\Users\\ssromerogon\\.conda\\envs\\audio_processing\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "c:\\Users\\ssromerogon\\.conda\\envs\\audio_processing\\lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "import whisper\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Ensure the NLTK packages are downloaded (only need to run once)\n",
    "nltk.data.path.append('C:/Users/ssromerogon/Documents/vscode_working_dir/meeting_minutes_processing/')  # Add the path where nltk data is stored\n",
    "nltk.download('punkt', download_dir='C:/Users/ssromerogon/Documents/vscode_working_dir/meeting_minutes_processing/')  # Redownload punkt\n",
    "nltk.download('stopwords', download_dir='C:/Users/ssromerogon/Documents/vscode_working_dir/meeting_minutes_processing/')  # Redownload stopwords\n",
    "nltk.download('punkt_tab', download_dir='C:/Users/ssromerogon/Documents/vscode_working_dir/meeting_minutes_processing/')\n",
    "\n",
    "# 1. Convert MP3 to WAV using pydub\n",
    "audio_file = \"scdc_11_13_24.mp3\"\n",
    "wav_file = \"scdc_11_13_24.wav\"\n",
    "\n",
    "# Convert MP3 to WAV\n",
    "audio = AudioSegment.from_mp3(audio_file)\n",
    "audio.export(wav_file, format=\"wav\")\n",
    "\n",
    "# 2. Speech-to-Text Conversion using Whisper\n",
    "model = whisper.load_model(\"large\")  # You can use \"tiny\", \"small\", or \"large\" based on your system\n",
    "result = model.transcribe(audio_file)\n",
    "text = result[\"text\"]\n",
    "\n",
    "# Check if the transcription was successful\n",
    "if not text.strip():\n",
    "    print(\"Whisper model could not transcribe the audio. The text is empty.\")\n",
    "else:\n",
    "    try:\n",
    "        # Clean the text (remove extra spaces, non-printable characters)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()  # Remove multiple spaces and leading/trailing spaces\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Remove non-ASCII characters\n",
    "\n",
    "        # 3. Natural Language Processing (NLP)\n",
    "        # Tokenization\n",
    "        sentences = sent_tokenize(text)\n",
    "        words = word_tokenize(text)\n",
    "\n",
    "        # Stop Word Removal\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "        # Stemming\n",
    "        stemmer = PorterStemmer()\n",
    "        stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "\n",
    "        # 4. Enhanced Meeting Minute Generation\n",
    "        def generate_minutes(sentences):\n",
    "            minutes = []\n",
    "            \n",
    "            # Define a set of keywords and phrases related to action items and decisions\n",
    "            action_keywords = [\n",
    "                \"action item\", \"decision\", \"next steps\", \"plan\", \"task\", \"should do\", \n",
    "                \"must do\", \"follow up\", \"agenda\", \"to do\", \"next task\", \"experiment\"\n",
    "            ]\n",
    "            \n",
    "            decision_keywords = [\n",
    "                \"decide\", \"decision\", \"conclude\", \"agree\", \"determine\", \"should\", \"feel confident\", \n",
    "                \"ready to launch\", \"launch\", \"plan the big experiment\", \"recruiting\"\n",
    "            ]\n",
    "            \n",
    "            experiment_related_phrases = [\n",
    "                \"experiment\", \"preliminary\", \"differential expression\", \"differential variability\", \n",
    "                \"spatial domain\", \"biology is changing\", \"exciting ways\", \"cells\", \"cell type\", \n",
    "                \"annotation\"\n",
    "            ]\n",
    "            \n",
    "            collaboration_phrases = [\n",
    "                \"shed light\", \"help us\", \"ready to launch\", \"prepared\", \"recruiting\", \"launch into\"\n",
    "            ]\n",
    "            \n",
    "            for sentence in sentences:\n",
    "                # Look for action items or decision-related sentences\n",
    "                if any(keyword in sentence.lower() for keyword in action_keywords):\n",
    "                    minutes.append(sentence)\n",
    "                elif any(keyword in sentence.lower() for keyword in decision_keywords):\n",
    "                    minutes.append(sentence)\n",
    "                elif any(phrase in sentence.lower() for phrase in experiment_related_phrases):\n",
    "                    minutes.append(sentence)\n",
    "                elif any(phrase in sentence.lower() for phrase in collaboration_phrases):\n",
    "                    minutes.append(sentence)\n",
    "            return minutes\n",
    "\n",
    "        # Generate meeting minutes\n",
    "        meeting_minutes = generate_minutes(sentences)\n",
    "\n",
    "        # 5. Save Raw Text and Meeting Minutes to Text Files\n",
    "        raw_text_file = \"raw_transcribed_text.txt\"\n",
    "        with open(raw_text_file, \"w\") as f:\n",
    "            f.write(text)\n",
    "\n",
    "        # Save Meeting Minutes\n",
    "        output_file = \"meeting_minutes.txt\"\n",
    "        with open(output_file, \"w\") as f:\n",
    "            for line in meeting_minutes:\n",
    "                f.write(line + \"\\n\")\n",
    "\n",
    "        print(\"Raw text and meeting minutes saved.\")\n",
    "        print(f\"Raw text saved to {raw_text_file}\")\n",
    "        print(f\"Meeting minutes saved to {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error during tokenization or NLP processing:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
